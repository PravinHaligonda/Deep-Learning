{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.autograd.Variable(torch.FloatTensor(np.array([[0,0],[0,1],[1,0],[1,1]])),requires_grad=False).to(device)\n",
    "y = torch.autograd.Variable(torch.FloatTensor(np.array([[0,1,1,0]]).T),requires_grad=False).to(device)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_xor = nn.Sequential(nn.Linear(2, 2),nn.ReLU(),nn.Linear(2,1)).to(device)\n",
    "net_xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 1)\n",
    "\n",
    "weights_init(net_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_net_xor = optim.SGD(net_xor.parameters(), lr=0.002, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5170, -0.7858, -3.1018, -3.3543], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.4688, -0.7163, -2.9638, -3.1949], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.4099, -0.6238, -2.7770, -2.9800], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.3771, -0.5173, -2.5566, -2.7274], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.3393, -0.4046, -2.3159, -2.4531], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.2976, -0.3147, -2.0666, -2.1710], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.2532, -0.2704, -1.8191, -1.8942], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.2069, -0.2243, -1.5798, -1.6296], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.1595, -0.1771, -1.3531, -1.3817], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.1117, -0.1295, -1.1417, -1.1532], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.0640, -0.0821, -0.9469, -0.9452], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.0170, -0.0353, -0.7692, -0.7577], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([ 0.0289,  0.0104, -0.6083, -0.5900], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([ 0.0735,  0.0548, -0.4633, -0.4407], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([ 0.1164,  0.0976, -0.3333, -0.3085], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([ 0.1575,  0.1385, -0.2170, -0.1917], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([ 0.1966,  0.1775, -0.1131, -0.0887], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([ 0.2337,  0.2145, -0.0204,  0.0022], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.2687, 0.2494, 0.0622, 0.0822], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.3015, 0.2821, 0.1358, 0.1527], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.3322, 0.3128, 0.2013, 0.2148], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.3608, 0.3413, 0.2598, 0.2697], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.3872, 0.3677, 0.3119, 0.3181], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4117, 0.3922, 0.3583, 0.3608], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4342, 0.4146, 0.3997, 0.3986], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4547, 0.4352, 0.4365, 0.4319], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4735, 0.4540, 0.4692, 0.4614], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4904, 0.4711, 0.4983, 0.4873], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5058, 0.4864, 0.5242, 0.5102], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.25\n",
      "tensor([0.5195, 0.5003, 0.5470, 0.5302], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5317, 0.5126, 0.5672, 0.5478], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5426, 0.5235, 0.5849, 0.5631], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5521, 0.5331, 0.6004, 0.5764], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5603, 0.5415, 0.6139, 0.5878], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5674, 0.5488, 0.6256, 0.5976], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5734, 0.5549, 0.6356, 0.6059], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5784, 0.5601, 0.6441, 0.6128], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5825, 0.5643, 0.6513, 0.6185], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5857, 0.5677, 0.6572, 0.6230], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5881, 0.5702, 0.6619, 0.6265], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5898, 0.5721, 0.6657, 0.6291], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5908, 0.5733, 0.6685, 0.6309], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5912, 0.5739, 0.6705, 0.6319], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5911, 0.5740, 0.6717, 0.6323], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5905, 0.5735, 0.6723, 0.6320], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5894, 0.5726, 0.6723, 0.6312], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5879, 0.5714, 0.6717, 0.6299], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5861, 0.5697, 0.6707, 0.6282], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5840, 0.5678, 0.6692, 0.6262], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5789, 0.5632, 0.6653, 0.6211], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5761, 0.5605, 0.6629, 0.6182], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5731, 0.5577, 0.6603, 0.6151], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5699, 0.5547, 0.6575, 0.6119], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5667, 0.5517, 0.6545, 0.6085], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5633, 0.5485, 0.6514, 0.6049], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5599, 0.5453, 0.6483, 0.6014], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5564, 0.5420, 0.6450, 0.5977], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5530, 0.5387, 0.6417, 0.5940], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5495, 0.5354, 0.6384, 0.5904], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5460, 0.5321, 0.6351, 0.5867], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5425, 0.5288, 0.6318, 0.5830], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5391, 0.5256, 0.6285, 0.5794], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5357, 0.5223, 0.6253, 0.5758], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5323, 0.5192, 0.6221, 0.5723], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5291, 0.5161, 0.6190, 0.5688], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5258, 0.5130, 0.6159, 0.5654], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5227, 0.5101, 0.6130, 0.5621], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5197, 0.5072, 0.6101, 0.5589], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5167, 0.5044, 0.6073, 0.5558], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5138, 0.5016, 0.6046, 0.5528], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.5110, 0.4990, 0.6021, 0.5498], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.25\n",
      "tensor([0.5084, 0.4965, 0.5996, 0.5470], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.25\n",
      "tensor([0.5058, 0.4940, 0.5972, 0.5443], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.25\n",
      "tensor([0.5033, 0.4917, 0.5950, 0.5417], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.25\n",
      "tensor([0.5009, 0.4894, 0.5928, 0.5392], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.25\n",
      "tensor([0.4986, 0.4873, 0.5908, 0.5368], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4964, 0.4852, 0.5889, 0.5345], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4943, 0.4832, 0.5871, 0.5323], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4923, 0.4813, 0.5854, 0.5302], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4904, 0.4796, 0.5838, 0.5282], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4885, 0.4779, 0.5823, 0.5263], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4868, 0.4762, 0.5809, 0.5245], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4852, 0.4747, 0.5796, 0.5228], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4836, 0.4733, 0.5784, 0.5212], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4821, 0.4719, 0.5773, 0.5197], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4807, 0.4706, 0.5763, 0.5182], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4794, 0.4694, 0.5753, 0.5169], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4782, 0.4683, 0.5745, 0.5156], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4770, 0.4672, 0.5737, 0.5144], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4759, 0.4663, 0.5731, 0.5132], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4749, 0.4653, 0.5725, 0.5122], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4739, 0.4645, 0.5719, 0.5112], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4730, 0.4637, 0.5715, 0.5103], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4722, 0.4629, 0.5711, 0.5094], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4714, 0.4622, 0.5708, 0.5086], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4707, 0.4616, 0.5705, 0.5078], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4700, 0.4610, 0.5703, 0.5071], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4693, 0.4604, 0.5701, 0.5065], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4682, 0.4595, 0.5700, 0.5053], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4677, 0.4590, 0.5700, 0.5047], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4672, 0.4586, 0.5700, 0.5043], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4668, 0.4583, 0.5701, 0.5038], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4664, 0.4580, 0.5702, 0.5034], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4660, 0.4577, 0.5703, 0.5030], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4657, 0.4574, 0.5705, 0.5026], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4653, 0.4572, 0.5707, 0.5023], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4651, 0.4570, 0.5709, 0.5019], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4648, 0.4568, 0.5712, 0.5016], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4645, 0.4566, 0.5715, 0.5013], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4643, 0.4564, 0.5718, 0.5011], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4641, 0.4563, 0.5721, 0.5008], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4639, 0.4562, 0.5725, 0.5006], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4637, 0.4561, 0.5728, 0.5004], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4636, 0.4560, 0.5732, 0.5002], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4634, 0.4559, 0.5736, 0.5000], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4633, 0.4558, 0.5740, 0.4998], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4632, 0.4558, 0.5744, 0.4996], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4631, 0.4557, 0.5749, 0.4994], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4630, 0.4557, 0.5753, 0.4992], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4629, 0.4557, 0.5758, 0.4990], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4628, 0.4556, 0.5762, 0.4989], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4627, 0.4556, 0.5767, 0.4987], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4626, 0.4556, 0.5772, 0.4985], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4625, 0.4556, 0.5776, 0.4983], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4625, 0.4556, 0.5781, 0.4982], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4624, 0.4555, 0.5786, 0.4980], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4623, 0.4555, 0.5791, 0.4978], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4623, 0.4555, 0.5796, 0.4976], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4622, 0.4555, 0.5801, 0.4975], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4621, 0.4555, 0.5806, 0.4973], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4621, 0.4555, 0.5811, 0.4971], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4620, 0.4555, 0.5816, 0.4969], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4620, 0.4555, 0.5821, 0.4967], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4619, 0.4555, 0.5826, 0.4965], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4619, 0.4555, 0.5831, 0.4963], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4618, 0.4555, 0.5836, 0.4961], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4618, 0.4555, 0.5841, 0.4959], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4617, 0.4555, 0.5846, 0.4956], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4617, 0.4555, 0.5851, 0.4954], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4616, 0.4555, 0.5856, 0.4952], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4615, 0.4555, 0.5861, 0.4949], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4615, 0.4555, 0.5866, 0.4947], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4614, 0.4555, 0.5871, 0.4944], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4614, 0.4555, 0.5876, 0.4941], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4613, 0.4555, 0.5881, 0.4939], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4613, 0.4555, 0.5886, 0.4936], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4612, 0.4554, 0.5891, 0.4933], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4611, 0.4554, 0.5901, 0.4927], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4610, 0.4554, 0.5906, 0.4924], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4609, 0.4554, 0.5911, 0.4921], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4609, 0.4554, 0.5916, 0.4918], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4608, 0.4553, 0.5921, 0.4914], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4607, 0.4553, 0.5926, 0.4911], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4607, 0.4553, 0.5931, 0.4908], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4606, 0.4553, 0.5935, 0.4904], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4606, 0.4552, 0.5940, 0.4901], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4605, 0.4552, 0.5945, 0.4897], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4604, 0.4552, 0.5950, 0.4893], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4604, 0.4552, 0.5955, 0.4889], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4603, 0.4551, 0.5960, 0.4885], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4602, 0.4551, 0.5965, 0.4882], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4601, 0.4551, 0.5970, 0.4878], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4601, 0.4551, 0.5974, 0.4873], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4600, 0.4550, 0.5979, 0.4869], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4599, 0.4550, 0.5984, 0.4865], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4599, 0.4550, 0.5989, 0.4861], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4598, 0.4549, 0.5994, 0.4856], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4598, 0.4549, 0.5999, 0.4852], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4597, 0.4549, 0.6004, 0.4847], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4596, 0.4549, 0.6009, 0.4843], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4596, 0.4548, 0.6014, 0.4838], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4595, 0.4548, 0.6018, 0.4834], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4594, 0.4548, 0.6023, 0.4829], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4594, 0.4547, 0.6028, 0.4824], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4593, 0.4547, 0.6033, 0.4819], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4592, 0.4547, 0.6038, 0.4814], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4592, 0.4547, 0.6043, 0.4809], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4591, 0.4546, 0.6048, 0.4804], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4591, 0.4546, 0.6053, 0.4799], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4590, 0.4546, 0.6058, 0.4793], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4590, 0.4546, 0.6063, 0.4788], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4589, 0.4546, 0.6068, 0.4783], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4589, 0.4545, 0.6073, 0.4777], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4588, 0.4545, 0.6078, 0.4772], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4588, 0.4545, 0.6083, 0.4766], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4587, 0.4545, 0.6088, 0.4761], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4587, 0.4545, 0.6093, 0.4755], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4586, 0.4544, 0.6098, 0.4749], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4586, 0.4544, 0.6104, 0.4743], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4585, 0.4544, 0.6109, 0.4737], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4585, 0.4544, 0.6114, 0.4731], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4585, 0.4544, 0.6119, 0.4725], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4584, 0.4544, 0.6124, 0.4719], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4584, 0.4544, 0.6129, 0.4713], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4584, 0.4544, 0.6135, 0.4707], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4583, 0.4544, 0.6140, 0.4700], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4583, 0.4544, 0.6150, 0.4687], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4582, 0.4544, 0.6156, 0.4681], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4582, 0.4544, 0.6161, 0.4674], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4582, 0.4544, 0.6166, 0.4667], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4582, 0.4544, 0.6172, 0.4661], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4582, 0.4544, 0.6177, 0.4654], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4544, 0.6182, 0.4647], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4544, 0.6188, 0.4640], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4544, 0.6193, 0.4633], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4544, 0.6199, 0.4626], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4545, 0.6204, 0.4619], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4545, 0.6209, 0.4611], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4545, 0.6215, 0.4604], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4545, 0.6220, 0.4596], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4545, 0.6226, 0.4589], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4546, 0.6232, 0.4581], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4546, 0.6237, 0.4574], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4546, 0.6243, 0.4566], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4546, 0.6248, 0.4558], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4547, 0.6254, 0.4550], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4547, 0.6260, 0.4542], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4547, 0.6265, 0.4534], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4582, 0.4548, 0.6271, 0.4526], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4582, 0.4548, 0.6277, 0.4518], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4582, 0.4549, 0.6282, 0.4510], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4582, 0.4549, 0.6288, 0.4502], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4582, 0.4549, 0.6294, 0.4493], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4583, 0.4550, 0.6300, 0.4485], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4583, 0.4550, 0.6306, 0.4476], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4583, 0.4551, 0.6312, 0.4467], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4584, 0.4552, 0.6317, 0.4459], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4584, 0.4552, 0.6323, 0.4450], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4584, 0.4553, 0.6329, 0.4441], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4585, 0.4553, 0.6335, 0.4438], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4585, 0.4554, 0.6343, 0.4438], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4586, 0.4555, 0.6351, 0.4439], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4586, 0.4555, 0.6361, 0.4440], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4586, 0.4556, 0.6372, 0.4441], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4587, 0.4556, 0.6385, 0.4441], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4587, 0.4557, 0.6398, 0.4442], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4588, 0.4557, 0.6411, 0.4443], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4588, 0.4558, 0.6426, 0.4443], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4588, 0.4558, 0.6441, 0.4444], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4588, 0.4558, 0.6457, 0.4444], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4588, 0.4559, 0.6473, 0.4444], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4588, 0.4559, 0.6490, 0.4445], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4588, 0.4559, 0.6507, 0.4451], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4588, 0.4559, 0.6523, 0.4456], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4587, 0.4558, 0.6537, 0.4460], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4586, 0.4557, 0.6563, 0.4462], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4585, 0.4557, 0.6574, 0.4461], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4584, 0.4556, 0.6585, 0.4458], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4583, 0.4555, 0.6595, 0.4454], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4582, 0.4554, 0.6604, 0.4449], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4581, 0.4553, 0.6612, 0.4444], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4579, 0.4552, 0.6620, 0.4439], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4578, 0.4551, 0.6629, 0.4438], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4577, 0.4549, 0.6639, 0.4437], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4575, 0.4548, 0.6650, 0.4436], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4573, 0.4546, 0.6661, 0.4434], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4572, 0.4545, 0.6674, 0.4433], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4570, 0.4543, 0.6687, 0.4431], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4568, 0.4542, 0.6702, 0.4431], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4566, 0.4540, 0.6714, 0.4432], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4564, 0.4538, 0.6726, 0.4431], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4562, 0.4536, 0.6737, 0.4429], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4560, 0.4534, 0.6746, 0.4425], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4558, 0.4532, 0.6755, 0.4420], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4556, 0.4530, 0.6765, 0.4418], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4553, 0.4528, 0.6775, 0.4416], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4551, 0.4526, 0.6787, 0.4414], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4549, 0.4523, 0.6800, 0.4413], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4546, 0.4521, 0.6811, 0.4412], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4544, 0.4519, 0.6821, 0.4409], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4541, 0.4516, 0.6830, 0.4405], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4538, 0.4514, 0.6841, 0.4402], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4536, 0.4511, 0.6852, 0.4400], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4533, 0.4509, 0.6862, 0.4397], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4530, 0.4506, 0.6873, 0.4395], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4528, 0.4503, 0.6883, 0.4392], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4525, 0.4501, 0.6894, 0.4389], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4522, 0.4498, 0.6906, 0.4388], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4519, 0.4495, 0.6917, 0.4386], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4516, 0.4492, 0.6926, 0.4381], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4514, 0.4490, 0.6934, 0.4378], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4511, 0.4487, 0.6944, 0.4375], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4508, 0.4484, 0.6955, 0.4372], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4505, 0.4481, 0.6966, 0.4369], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4502, 0.4478, 0.6979, 0.4368], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4499, 0.4475, 0.6990, 0.4366], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4496, 0.4473, 0.7000, 0.4362], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4493, 0.4470, 0.7009, 0.4357], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4490, 0.4467, 0.7018, 0.4354], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4487, 0.4464, 0.7029, 0.4351], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4484, 0.4461, 0.7041, 0.4350], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4480, 0.4458, 0.7052, 0.4347], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4477, 0.4455, 0.7061, 0.4342], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4474, 0.4452, 0.7069, 0.4338], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4468, 0.4446, 0.7089, 0.4332], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4465, 0.4443, 0.7101, 0.4329], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4462, 0.4440, 0.7113, 0.4326], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4459, 0.4436, 0.7124, 0.4324], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4456, 0.4433, 0.7134, 0.4319], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4452, 0.4430, 0.7142, 0.4316], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4449, 0.4427, 0.7152, 0.4312], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4446, 0.4424, 0.7162, 0.4309], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4443, 0.4421, 0.7174, 0.4306], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4440, 0.4418, 0.7187, 0.4305], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4437, 0.4415, 0.7198, 0.4302], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4434, 0.4412, 0.7208, 0.4298], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4430, 0.4409, 0.7216, 0.4292], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4427, 0.4406, 0.7226, 0.4289], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4424, 0.4403, 0.7236, 0.4285], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4421, 0.4400, 0.7248, 0.4282], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4418, 0.4396, 0.7258, 0.4279], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4415, 0.4393, 0.7267, 0.4275], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4412, 0.4390, 0.7277, 0.4272], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4408, 0.4387, 0.7288, 0.4268], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4405, 0.4384, 0.7300, 0.4266], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4402, 0.4381, 0.7311, 0.4262], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4399, 0.4378, 0.7320, 0.4258], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4396, 0.4375, 0.7330, 0.4254], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4393, 0.4372, 0.7342, 0.4251], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4390, 0.4369, 0.7351, 0.4247], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4387, 0.4366, 0.7362, 0.4244], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4383, 0.4363, 0.7374, 0.4242], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4380, 0.4360, 0.7384, 0.4239], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4377, 0.4356, 0.7393, 0.4233], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4374, 0.4353, 0.7403, 0.4230], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4371, 0.4350, 0.7414, 0.4226], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4368, 0.4347, 0.7426, 0.4225], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4365, 0.4344, 0.7437, 0.4221], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4362, 0.4341, 0.7445, 0.4216], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4359, 0.4338, 0.7455, 0.4212], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4355, 0.4335, 0.7466, 0.4208], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4352, 0.4332, 0.7479, 0.4207], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4349, 0.4329, 0.7489, 0.4204], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4346, 0.4326, 0.7497, 0.4198], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4343, 0.4323, 0.7507, 0.4194], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4340, 0.4320, 0.7518, 0.4191], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4337, 0.4317, 0.7528, 0.4187], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4334, 0.4314, 0.7538, 0.4183], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4331, 0.4311, 0.7550, 0.4180], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4328, 0.4308, 0.7560, 0.4176], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4325, 0.4305, 0.7570, 0.4173], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4322, 0.4302, 0.7580, 0.4169], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4319, 0.4299, 0.7590, 0.4165], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4313, 0.4293, 0.7611, 0.4157], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4310, 0.4290, 0.7622, 0.4154], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4307, 0.4287, 0.7633, 0.4152], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4304, 0.4284, 0.7643, 0.4148], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4300, 0.4281, 0.7651, 0.4143], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4297, 0.4278, 0.7660, 0.4139], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4295, 0.4275, 0.7671, 0.4135], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4292, 0.4272, 0.7683, 0.4132], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4289, 0.4269, 0.7695, 0.4130], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4286, 0.4266, 0.7706, 0.4127], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4283, 0.4263, 0.7714, 0.4121], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4280, 0.4260, 0.7721, 0.4117], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4277, 0.4257, 0.7729, 0.4113], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4274, 0.4254, 0.7739, 0.4109], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4271, 0.4251, 0.7749, 0.4105], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4268, 0.4249, 0.7761, 0.4102], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4265, 0.4246, 0.7774, 0.4098], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4262, 0.4243, 0.7787, 0.4097], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4259, 0.4240, 0.7798, 0.4095], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4256, 0.4237, 0.7808, 0.4090], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4253, 0.4234, 0.7815, 0.4083], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4250, 0.4231, 0.7823, 0.4079], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4247, 0.4229, 0.7833, 0.4075], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4245, 0.4226, 0.7844, 0.4071], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4242, 0.4223, 0.7856, 0.4068], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4239, 0.4220, 0.7866, 0.4064], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4236, 0.4217, 0.7873, 0.4060], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4233, 0.4214, 0.7882, 0.4056], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4230, 0.4212, 0.7892, 0.4052], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4227, 0.4209, 0.7903, 0.4048], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4225, 0.4206, 0.7916, 0.4045], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4222, 0.4203, 0.7925, 0.4041], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4219, 0.4201, 0.7933, 0.4037], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4216, 0.4198, 0.7942, 0.4033], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4213, 0.4195, 0.7952, 0.4029], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4211, 0.4192, 0.7963, 0.4025], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4208, 0.4190, 0.7975, 0.4024], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4205, 0.4187, 0.7985, 0.4020], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4202, 0.4184, 0.7993, 0.4013], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4200, 0.4182, 0.8001, 0.4010], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4197, 0.4179, 0.8011, 0.4006], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4194, 0.4176, 0.8022, 0.4002], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4191, 0.4174, 0.8031, 0.3998], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4189, 0.4171, 0.8041, 0.3994], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4186, 0.4168, 0.8052, 0.3991], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4183, 0.4166, 0.8060, 0.3986], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4180, 0.4163, 0.8070, 0.3982], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4178, 0.4161, 0.8080, 0.3979], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4175, 0.4158, 0.8088, 0.3974], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4170, 0.4153, 0.8108, 0.3967], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4167, 0.4150, 0.8116, 0.3963], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4165, 0.4148, 0.8126, 0.3959], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4162, 0.4145, 0.8136, 0.3955], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4159, 0.4143, 0.8147, 0.3953], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4157, 0.4140, 0.8156, 0.3948], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4154, 0.4138, 0.8162, 0.3943], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4151, 0.4135, 0.8170, 0.3939], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4149, 0.4133, 0.8179, 0.3935], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4146, 0.4130, 0.8189, 0.3931], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4144, 0.4128, 0.8200, 0.3927], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4141, 0.4126, 0.8211, 0.3925], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4139, 0.4123, 0.8220, 0.3921], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4136, 0.4121, 0.8227, 0.3915], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4134, 0.4118, 0.8235, 0.3911], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4131, 0.4116, 0.8244, 0.3907], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4129, 0.4114, 0.8254, 0.3903], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4126, 0.4112, 0.8265, 0.3900], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4124, 0.4109, 0.8273, 0.3895], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4121, 0.4107, 0.8283, 0.3891], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4119, 0.4105, 0.8289, 0.3887], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4117, 0.4102, 0.8297, 0.3883], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4114, 0.4100, 0.8306, 0.3879], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4112, 0.4098, 0.8316, 0.3875], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4109, 0.4096, 0.8327, 0.3873], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4107, 0.4094, 0.8336, 0.3868], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4105, 0.4091, 0.8341, 0.3863], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4102, 0.4089, 0.8348, 0.3859], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4100, 0.4087, 0.8356, 0.3855], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4098, 0.4085, 0.8365, 0.3851], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4096, 0.4083, 0.8375, 0.3847], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4093, 0.4081, 0.8386, 0.3843], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4091, 0.4079, 0.8398, 0.3843], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4089, 0.4077, 0.8407, 0.3839], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4086, 0.4075, 0.8413, 0.3832], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4084, 0.4073, 0.8416, 0.3827], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4082, 0.4071, 0.8421, 0.3823], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4080, 0.4069, 0.8427, 0.3819], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4078, 0.4067, 0.8435, 0.3815], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4076, 0.4065, 0.8443, 0.3811], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4073, 0.4063, 0.8453, 0.3807], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4071, 0.4062, 0.8463, 0.3803], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4069, 0.4060, 0.8475, 0.3799], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4067, 0.4058, 0.8487, 0.3795], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4065, 0.4056, 0.8499, 0.3797], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4063, 0.4054, 0.8508, 0.3794], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4061, 0.4053, 0.8515, 0.3787], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4059, 0.4051, 0.8518, 0.3779], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4057, 0.4049, 0.8523, 0.3775], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4053, 0.4046, 0.8537, 0.3767], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4051, 0.4044, 0.8545, 0.3763], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4049, 0.4043, 0.8554, 0.3759], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4047, 0.4041, 0.8564, 0.3755], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4045, 0.4039, 0.8575, 0.3751], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4043, 0.4038, 0.8583, 0.3747], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4041, 0.4036, 0.8587, 0.3742], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4039, 0.4035, 0.8593, 0.3738], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4037, 0.4033, 0.8600, 0.3734], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4035, 0.4032, 0.8608, 0.3730], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4034, 0.4030, 0.8617, 0.3726], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4032, 0.4029, 0.8627, 0.3722], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4030, 0.4028, 0.8637, 0.3721], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4028, 0.4026, 0.8644, 0.3716], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4026, 0.4025, 0.8649, 0.3710], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4025, 0.4024, 0.8654, 0.3706], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4023, 0.4022, 0.8660, 0.3702], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4021, 0.4021, 0.8668, 0.3698], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4019, 0.4020, 0.8676, 0.3694], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4018, 0.4019, 0.8685, 0.3690], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4016, 0.4018, 0.8695, 0.3687], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4014, 0.4016, 0.8702, 0.3683], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4013, 0.4015, 0.8705, 0.3677], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4011, 0.4014, 0.8710, 0.3673], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4009, 0.4013, 0.8716, 0.3669], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4008, 0.4012, 0.8723, 0.3665], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4006, 0.4011, 0.8731, 0.3661], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4005, 0.4010, 0.8739, 0.3657], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4003, 0.4009, 0.8749, 0.3653], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4002, 0.4008, 0.8759, 0.3651], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.4000, 0.4007, 0.8765, 0.3647], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3999, 0.4007, 0.8768, 0.3640], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3997, 0.4006, 0.8773, 0.3636], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3996, 0.4005, 0.8779, 0.3632], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3994, 0.4004, 0.8785, 0.3628], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3993, 0.4003, 0.8793, 0.3624], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3991, 0.4003, 0.8801, 0.3620], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3990, 0.4002, 0.8810, 0.3616], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3989, 0.4001, 0.8820, 0.3616], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3987, 0.4001, 0.8826, 0.3611], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3986, 0.4000, 0.8828, 0.3603], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3984, 0.4000, 0.8832, 0.3599], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3983, 0.3999, 0.8838, 0.3595], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3982, 0.3999, 0.8844, 0.3591], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3981, 0.3998, 0.8850, 0.3587], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3979, 0.3998, 0.8858, 0.3582], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3978, 0.3997, 0.8867, 0.3578], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3977, 0.3997, 0.8876, 0.3578], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3976, 0.3997, 0.8881, 0.3573], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n"
     ]
    }
   ],
   "source": [
    "net_xor.train()\n",
    "for i in range(500):\n",
    "    optimizer_net_xor.zero_grad()\n",
    "    output = net_xor(X)\n",
    "    if i%50:\n",
    "        print(output.squeeze())\n",
    "        print('Accuracy: ', ((output.squeeze()>0.5)==y.squeeze().byte()).sum().item()/4)\n",
    "    loss = F.mse_loss(output, y)\n",
    "    loss.backward()\n",
    "    optimizer_net_xor.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3975],\n",
       "        [0.3996],\n",
       "        [0.8883],\n",
       "        [0.3566]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_xor.eval()\n",
    "output = net_xor(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[-1.1635,  0.0189],\n",
      "        [ 1.4331, -0.7001]])\n",
      "0.bias tensor([ 0.3516, -0.7334])\n",
      "2.weight tensor([[0.1162, 0.7600]])\n",
      "2.bias tensor([0.3566])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net_xor.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:21<00:00, 456402.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 46794.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:07<00:00, 225357.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_random_images(loader):\n",
    "    rand_idxs = [np.random.randint(0, batch_size-1) for i in range (4)]\n",
    "    for t in loader:\n",
    "        X = t[0][rand_idxs]\n",
    "        y = t[1][rand_idxs]\n",
    "\n",
    "        print(X.shape, y.shape)\n",
    "\n",
    "        f, axarr = plt.subplots(2,2)\n",
    "\n",
    "        axarr[0,0].imshow(X[0].squeeze())\n",
    "        axarr[0,0].set_title(str(y[0].item()))\n",
    "\n",
    "        axarr[0,1].imshow(X[1].squeeze())\n",
    "        axarr[0,1].set_title(str(y[1].item()))\n",
    "\n",
    "        axarr[1,0].imshow(X[2].squeeze())\n",
    "        axarr[1,0].set_title(str(y[2].item()))\n",
    "\n",
    "        axarr[1,1].imshow(X[3].squeeze())\n",
    "        axarr[1,1].set_title(str(y[3].item()))\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = draw_random_images(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDenseNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleDenseNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc_output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        return F.log_softmax(self.fc_output(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleDenseNet(\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc_output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = SimpleDenseNet(28*28).to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Batch Accuracy: ', (torch.argmax(output,1) == target).sum().item()/batch_size)\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halig\\AppData\\Local\\Temp\\ipykernel_3128\\1259087578.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(self.fc_output(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Accuracy:  0.03125\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 2.321407\n",
      "Batch Accuracy:  0.15625\n",
      "Train Epoch: 50 [1600/60000 (3%)]\tLoss: 2.290150\n",
      "Batch Accuracy:  0.25\n",
      "Train Epoch: 50 [3200/60000 (5%)]\tLoss: 2.255454\n",
      "Batch Accuracy:  0.25\n",
      "Train Epoch: 50 [4800/60000 (8%)]\tLoss: 2.262258\n",
      "Batch Accuracy:  0.25\n",
      "Train Epoch: 50 [6400/60000 (11%)]\tLoss: 2.250042\n",
      "Batch Accuracy:  0.21875\n",
      "Train Epoch: 50 [8000/60000 (13%)]\tLoss: 2.245552\n",
      "Batch Accuracy:  0.3125\n",
      "Train Epoch: 50 [9600/60000 (16%)]\tLoss: 2.230746\n",
      "Batch Accuracy:  0.28125\n",
      "Train Epoch: 50 [11200/60000 (19%)]\tLoss: 2.220270\n",
      "Batch Accuracy:  0.40625\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 2.181601\n",
      "Batch Accuracy:  0.53125\n",
      "Train Epoch: 50 [14400/60000 (24%)]\tLoss: 2.185799\n",
      "Batch Accuracy:  0.6875\n",
      "Train Epoch: 50 [16000/60000 (27%)]\tLoss: 2.146823\n",
      "Batch Accuracy:  0.46875\n",
      "Train Epoch: 50 [17600/60000 (29%)]\tLoss: 2.156515\n",
      "Batch Accuracy:  0.5\n",
      "Train Epoch: 50 [19200/60000 (32%)]\tLoss: 2.157043\n",
      "Batch Accuracy:  0.625\n",
      "Train Epoch: 50 [20800/60000 (35%)]\tLoss: 2.100584\n",
      "Batch Accuracy:  0.4375\n",
      "Train Epoch: 50 [22400/60000 (37%)]\tLoss: 2.126570\n",
      "Batch Accuracy:  0.875\n",
      "Train Epoch: 50 [24000/60000 (40%)]\tLoss: 1.974277\n",
      "Batch Accuracy:  0.53125\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 2.027420\n",
      "Batch Accuracy:  0.5625\n",
      "Train Epoch: 50 [27200/60000 (45%)]\tLoss: 2.039991\n",
      "Batch Accuracy:  0.71875\n",
      "Train Epoch: 50 [28800/60000 (48%)]\tLoss: 1.958336\n",
      "Batch Accuracy:  0.8125\n",
      "Train Epoch: 50 [30400/60000 (51%)]\tLoss: 1.900696\n",
      "Batch Accuracy:  0.65625\n",
      "Train Epoch: 50 [32000/60000 (53%)]\tLoss: 1.867598\n",
      "Batch Accuracy:  0.65625\n",
      "Train Epoch: 50 [33600/60000 (56%)]\tLoss: 1.878051\n",
      "Batch Accuracy:  0.625\n",
      "Train Epoch: 50 [35200/60000 (59%)]\tLoss: 1.846818\n",
      "Batch Accuracy:  0.6875\n",
      "Train Epoch: 50 [36800/60000 (61%)]\tLoss: 1.795040\n",
      "Batch Accuracy:  0.75\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 1.688018\n",
      "Batch Accuracy:  0.8125\n",
      "Train Epoch: 50 [40000/60000 (67%)]\tLoss: 1.673669\n",
      "Batch Accuracy:  0.6875\n",
      "Train Epoch: 50 [41600/60000 (69%)]\tLoss: 1.685332\n",
      "Batch Accuracy:  0.78125\n",
      "Train Epoch: 50 [43200/60000 (72%)]\tLoss: 1.485255\n",
      "Batch Accuracy:  0.71875\n",
      "Train Epoch: 50 [44800/60000 (75%)]\tLoss: 1.585840\n",
      "Batch Accuracy:  0.75\n",
      "Train Epoch: 50 [46400/60000 (77%)]\tLoss: 1.506872\n",
      "Batch Accuracy:  0.75\n",
      "Train Epoch: 50 [48000/60000 (80%)]\tLoss: 1.372826\n",
      "Batch Accuracy:  0.75\n",
      "Train Epoch: 50 [49600/60000 (83%)]\tLoss: 1.461910\n",
      "Batch Accuracy:  0.78125\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 1.273606\n",
      "Batch Accuracy:  0.8125\n",
      "Train Epoch: 50 [52800/60000 (88%)]\tLoss: 1.366129\n",
      "Batch Accuracy:  0.625\n",
      "Train Epoch: 50 [54400/60000 (91%)]\tLoss: 1.336830\n",
      "Batch Accuracy:  0.6875\n",
      "Train Epoch: 50 [56000/60000 (93%)]\tLoss: 1.362073\n",
      "Batch Accuracy:  0.75\n",
      "Train Epoch: 50 [57600/60000 (96%)]\tLoss: 1.206367\n",
      "Batch Accuracy:  0.875\n",
      "Train Epoch: 50 [59200/60000 (99%)]\tLoss: 0.954740\n"
     ]
    }
   ],
   "source": [
    "train(net, train_loader, optimizer, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halig\\AppData\\Local\\Temp\\ipykernel_3128\\1259087578.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(self.fc_output(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1153, Accuracy: 7845/10000 (78%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = draw_random_images(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halig\\AppData\\Local\\Temp\\ipykernel_3128\\1259087578.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(self.fc_output(x))\n"
     ]
    }
   ],
   "source": [
    "predicted_y = net(X).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 7])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 7])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
